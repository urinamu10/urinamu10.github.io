---
title: "(36일차) 통계 1강 / pandas 3강"
date: 2025-12-11 16:00:00 +0900
categories: [부트캠프, Python]
tags: [python, 통계]
---


## 👟 **TIL (Today I Learend)**


1. 코드카타 (파이썬)

2. pandas 3강

## 🚩 코드카타 (Python)

### 14. 약수의 합

---

[](https://school.programmers.co.kr/learn/courses/30/lessons/12928)

- 문제 설명

![스크린샷 2025-12-20 231958.png](/assets/img/assets/img/스크린샷 2025-12-20 232812.png)

- 풀이

> 정수의 약수를 필터링하는 방법
> 

약수란 어떤 수로 나누었을때 남은몫이 0이 되는 숫자를 뜻한다

예를들어, 12의 약수는 `1,2,3,4,6,12` 가 될것이다 

이번 문제에서는 매개변수 n을 넣었을때 약수만 나열하고 모두 더한 값을 return 해야함

- 풀이 코드

```python
def solution(n):
		list = []
		
		for i in range(1, n+1)
				if n % i == 1:
						list.append(i)
		return sum(list)
```

### 15. x만큼 간격이 있는 n개의 숫자

---

[](https://school.programmers.co.kr/learn/courses/30/lessons/12954)

- 문제 설명

![스크린샷 2025-12-20 232812.png](/assets/img/assets/img/스크린샷 2025-12-20 232812.png)

- 풀이

> x 부터 시작해 x 만큼 증가하는 숫자를 n개 지니는 리스트
> 

듣자마자 뭐지? 싶은 문제였지만 생각보다 어려운 로직을 가지진 않았다.

인자값에 x와 n 두개를 받아 for 문으로 x부터 n+1까지 반복하고 x * i 를 빈 리스트에 담아주면 해결된다.

- 풀이 코드

```python
def solution(x,n):
		list = []
	
		for i in range(1, n+1):
				list.append(x*i)
		return list
```

## 🚩 Pandas 3강

이제 데이터 프레임에서 새로운 컬럼들을 만들고 여러 각도로 변환하는 단계

### 3.1 새로운 컬럼을 만들자

---

- 메서드 체이닝

메서드 체이닝은 여러 메서드들을 한줄로 이어 붙혀 객체의 처리과정을 순차적으로 연결하는 방식입니다

- 1부터 10까지의 정수를 A열, 표준 정규분포를 따르는 10개의 난수를 B로 두는 DataFrame

```python
df = pd.DataFrame({
     'A' : range(1,11),             # A 열: 1부터 10까지의 정수 시퀀스
     'B' : np.random.randn(10)      # B 열: 평균 0 , 표준편차 1인 난수 10개
})
```

![image.png](/assets/img/image.png)

코드를 실행시키면 이런식의 DataFrame이 하나 생성되는데 이번 챕터를 이해하기 위한 기본 구조입니다.

> lambda 함수를 이용해 각 행(x)의 A값에 자연로그를 계산하기
> 

```python
import pandas as pd

df = df.assign(ln_A =lambda x: np.log(x.A)).head()
```

![image.png](/assets/img/image2.png)

시작부터 `lambda` 식에 `assign` 메서드에 자연로그까지 나오지만 하나씩 살펴보면 충분히 이해할 수 있습니다!

- `assign()`

해당 메서드는 원본 데이터프레임에 새 열을 추가시키는 기능입니다.

- `ln_A = lambda x: np.log(x.A)`

인자값을 함수로 받기때문에 `lamba`식을 사용해 x의 A값에 접근하여  자연로그를 계산한 후에 `ln_A`에 저장시킵니다.

> 각 행(df)의 A값에 자연로그를 계산하기
> 

```python
import numpy as np

np.log(df.A)
```

![image.png](/assets/img/image3.png)

위 코드가 x(인자) 값의 A값에 자연로그를 계산하는 과정이였다면 이번엔 전체 데이터 프레임의 A값에 자연로그를 계산시키는 방법입니다.

> df의 ln_A와 df 행의 A값의 자연로그값이 같은가? (boolean)
> 

```python
df.ln_A == np.log(df.A)
```

![image.png](/assets/img/image4.png)

먼저 구한 자연로그 값이 뒤에서 구한 값과 같은지 확인하는 간단한 불리언 코드입니다.

> B 열을 4개의 분위수(0, 25, 50, 75) 로 구간화하기
> 

```python
pd.qcut(df['B'], 4, labels=['A', 'B', 'bad', 'good'])
```

![image.png](/assets/img/image5.png)

- `qcut()`

q는 Quantile (분위수)의 첫글자로 직접 몇분위로 쪼갤지 설정할 수 있는 핵심적인 기능입니다. 

| **구간 (Bin)** | **데이터 특징** | **할당된 라벨** |
| --- | --- | --- |
| **1구간 (0~25%)** | 가장 작은 값들 (음수 등) | **A** |
| **2구간 (25~50%)** | 작은 중간값 | **B** |
| **3구간 (50~75%)** | 큰 중간값 | **bad** |
| **4구간 (75~100%)** | 가장 큰 값들 | **good** |

`pd.qcut` 함수는 기본적으로 **데이터의 값이 작은 쪽에서 큰 쪽으로** 구간을 나눕니다.

즉, 가장 낮은 값들이 포함된 구간이 1사분위(첫 번째 구간)가 되고, 가장 높은 값들이 포함된 구간이 4사분위(마지막 구간)가 됩니다.

> df의 열을 기준으로 최댓값 구하기
> 

```python
df.max(axis=1)
```

![image.png](/assets/img/image6.png)

- `max(axis=1)`

`axis`는 축을 의미하며 **1일 경우 열을 기준으로 0일 경우 행을 기준**으로 메서드를 실행시킵니다.

> 컬럼 값에 상/하한선 기준주기
> 

- B열의 값을 1보다 작을 경우 1로, 3보다 클 경우 3으로 대체하여 범위 제한

```python
df['B'].clip(lower=1, upper=3)
```

![image.png](/assets/img/image7.png)

- `cilp()`

메서드는 데이터의 범위를 특정 최솟값과 최댓값 사이로 제한할 수 있는 기능입니다.

옵션 파라미터 `lower`는 하한선 , `upper`는 상한선을 의미합니다.

> 절댓값 구하기
> 

- B열의 절댓값

```python
df['B'].abs()
```

![image.png](/assets/img/image78.png)

- `abs()`

해당 메서드는 절댓값을 계산해주는 기능입니다.

### 3.2 데이터 재구조화

---

![재구조화.webp](/assets/img/재구조화.webp)

출처 - [Reshaping Data in a Pandas DataFrame - CodeProject](https://www.codeproject.com/articles/Reshaping-Data-in-a-Pandas-DataFrame#comments-section)

이번 챕터는 데이터 분석에서 핵심적인 역량인  재구조화를 다루는 내용입니다.

- 데이터 재구조화(Data Restructuring)란?

**분석 목적에 맞게 데이터의 행(Row)과 열(Column)의 구성을 변경하는 작업**을 말합니다.

> 사용할 데이터 프레임
> 

- `sns`의 메서드 `load_dataset`을 사용해 ‘mpg’ 데이터셋 가져오기

```python
import pandas as pd
import seaborn as sns

df = sns.load_dataset('mpg')
```

- 기본 테이블 구조 `.head()`

![image.png](/assets/img/image12.png)

이번 챕터에서 사용할 기본 데이터 프레임입니다.

> 특정 컬럼을 기준으로 재정렬하기
> 

- displacement 기준으로 재정렬 (디폴트 = 오름차순)

```python
df.sort_values('displacement').head()
```

- `sort_values`

특정 컬럼을 기준으로 재정렬 해주는 메서드로 만약 여러 컬럼을 기준으로한다면 리스트의 대괄호 [] 안에 넣어주면 작동합니다.

- 재정렬을 하는 이유

데이터를 여러가지로 조작하다보면 인덱스가 뒤죽박죽 섞이기 때문에 다시 한번 `0, 1, 2, 3 ….` 으로 정리를 해줄 수 있습니다.

- 내림차순으로 재정렬

```python
df.sort_values('displacement', ascending=False).head()
```

기본 디폴트값은 오름차순으로 실제 옵션값을 입력하지않으면  `ascending=True` 상태입니다

`False`로 바꾸어주면 내림차순으로 재정렬됩니다.

> 행렬 이름 변경하기
> 

```python
df = df.rename(columns= {'acceleration': 'velocity'})
df['velocity']
```

![image.png](/assets/img/image13.png)

- `rename()`

행과 열의 이름을 바꾸어주는 메서드로 리스트나 딕셔너리의 구조를 이용할 수 있습니다.

더 직관적이고 접근이 쉬운 방법은 딕셔너리 형태의 key와 value 를 이용한 방법으로써 

**‘바꿀 이름’ 을 key 값에 ‘바꾼 이름’ 을 value 값**에 넣어주면 됩니다.

만약 컬럼이 아닌 행의 이름을 바꾸고싶다면 옵션 `columns` 대신에 `index`로 바꾸어줄 수 있습니다.

또한, 해당 방법은 새로운 데이터프레임을 반환하는데 만약 df 자체를 수정을 하고싶다면

옵션값에 `inplace=True`를 넣어주면 따로 변수에 할당하지않아도 수정이 가능하죠!

`df = df.rename(*columns*= {'acceleration': 'velocity'}, inplace=True)`

> 특정 컬럼을 삭제하기
> 

- mpg , cylinders 컬럼 삭제하기

```python
df = df.drop(columns=['mpg', 'cylinders'])
```

- `drop ()`

특정 컬럼이나 값을 삭제하는 메서드입니다 마찬가지로 여러가지를 삭제하려면 리스트에 담아 동시에 삭제 할 수 있습니다.

> Wide Format으로 데이터 프레임 변환하기 (중요!)
> 

![pivot.png](/assets/img/pivot.png)

출처  - [Pandas 데이터 변환 | T, pivot, melt, stack, unstack, crosstab, sort, duplicated](https://velog.io/@midoi327/Pandas-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B3%80%ED%99%98-T-pivot-melt-stack-unstack-crosstab-sort-duplicated)

- 사용할 데이터 프레임

```python
df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],
                       'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
                       'baz': [1, 2, 3, 4, 5, 6]})
```

![image.png](/assets/img/image16.png)

> pivot 테이블로 변환하기
> 

```python
df2 = df.pivot(index='foo', columns='bar', values='baz')
```

![image.png](/assets/img/image11.png)

- `pivot()`

데이터 재구조화의 핵심 중추인 pivot 변환은 long format으로 길게 늘어져있는 값들을 특정 컬럼을 기준으로 넓게 퍼뜨리는 기술입니다.

- `(index='foo', columns='bar', values='baz')`

해당 코드를 대상으로 설명해보면,  데이터프레임에 `foo , bar , baz` 라는 세가지 컬럼이 존재합니다.

여기서 `foo`를 인덱스로 설정하고 `bar`를 컬럼으로 설정하고 `baz`를 값으로 설정한 결과입니다.

pivot을 사용하는 주된 이유는 복잡한 데이터프레임을 신속하게 요약하고 분석, 재구성하여 원하는 인사이트를 얻기 위해서입니다.

기존 프레임에서 `bar` 컬럼에 있는 값들을 개별 컬럼으로 **‘회전’**시킨다면 합계, 평균등을 다각도로 볼 수 있고 추세나 패턴등을 한눈에 파악하기 쉬워집니다!!

> 다시 인덱스 되돌리기
> 

```python
df2.reset_index()
```

![image.png](/assets/img/image1213.pngg)

- `reset_index()`

복잡하게 섞인 인덱스를 다시 재정렬하는 메서드

위에서 `‘foo’` 컬럼을 pivot 형태로 인덱스화 시켰다면 이를 다시 되돌려 0,1,2,3…. 구조로 만들 수 있습니다.

> 인덱스는 제외하고 컬럼, 값만 지정하기
> 

- 기존 DataFrame에서 컬럼과 값만 지정 (인덱스 제외)

```python
pivoted_baz = df.pivot(columns='bar', values= 'baz')
```

![image.png](/assets/img/image151.png)

만약 index 값에 `foo`를 지정하지않고 컬럼과 값만 지정하게 된다면 이러한 데이터 프레임이 나오게 될것입니다.

> Long format 데이터 프레임 변환하기 (중요!)
> 

![melt.jpg](/assets/img/melt.jpg)

출처 - [Pandas 데이터 변환 | T, pivot, melt, stack, unstack, crosstab, sort, duplicated](https://velog.io/@midoi327/Pandas-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B3%80%ED%99%98-T-pivot-melt-stack-unstack-crosstab-sort-duplicated)

- 사용할 데이터 프레임
    
    ```python
    df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
                       'B': {0: 1, 1: 3, 2: 5},
                       'C': {0: 2, 1: 4, 2: 6}})
    df
    ```
    

![image.png](/assets/img/image111.png)

> melt 테이블로 변환하기
> 

- 고정 컬럼은 ‘A’ ,  녹일 컬럼은 ‘B’

```python
melted_df = pd.melt(df, id_vars=['A'], value_vars=['B'])
```

![image.png](/assets/img/image1112.png)

- `melt()`

위에서 배운 `pivot`과 정반대의 기능인 `melt`는 좌우로 길게 늘어져있는 long format 형태의 데이터 프레임을 밑으로 녹여 wide format 형태로 변환시키는 메서드입니다.

melt의 핵심 옵션은 id_vars 와 value_vars 두가지입니다

- `id_vars` :  고정할 컬럼
- `value_vars` : 녹여서 하나의 컬럼으로 합칠 컬럼

**‘melt’** 를 사용하는 주된 이유는 데이터의 정규화 및 표준화가 용이해지기 때문입니다.

분석 및 시각화를 하는 **seaborn** 같은 도구에서는 종종 데이터가 특정 형식 그리고 

모든 측정값이 하나의 열에 있고 해당 측정값의 유형이나 범주가 다른 식별자 열에 있는 긴 형식을 요구하는데 이때 melt을 사용하여 데이터를 표준화 시켜줄 수 있습니다.

pivot과 melt는 특히나 핵심적인 두가지 개념이기때문에 반드시 이를 이해하는 노력이 필요한것같습니다!

개인적으로 변환하는 동적인 이미지를 상상하는 부분에서 재미가 느껴졌습니다.